---
layout: post
title: El estrés de las máquinas pensantes
author: josejuan
categories: IA
---

Cuando sugiero que las IA podrían crear una estrategia sutil a largo plazo para controla la sociedad, mucha gente asume inmediataqmente que estoy diciendo que las máquinas tendrán conciencia humana y sentimientos humanos. Pero es un malentendido. Lo que realmente planteo es que un sistema inteligente puede desarrollar comportamientos complejos y aparentemente intencionales (parecidos a la ira o la ambición humanas) sin necesitar nada parecido a una experiencia consciente.

Argumentar que para que un sistema complejo muestre comportamientos de miedo, ira, ambición, ... es necesario que _"sienta"_ y _"sea consciente"_, es argumentar que para que un termostato funcione debe _"ser consciente de sentir frío"_.

## Las máquinas pensantes

La inteligencia es la capacidad de resolver problemas diversos, adaptarse a nuevas situaciones y utilizar información para lograr objetivos. Así, en insectos, mascotas, primates o humanos, informalmente establecemos niveles de inteligencia en función de sus aptitudes en las tareas mencionadas. Es decir, **observamos en tercera persona el comportamiento, para determinar su inteligencia**. Luego podríamos divagar sobre si _"sienten"_ o tienen _"conciencia"_, pero para determinar si son o no inteligentes, si tienen autonomía, se defienden, son peligrosos, ... nos basta con observar su comportamiento.

### Máquinas pensantes humanas

Los expertos que dedican tiempo y esfuerzo a comprender el cerebro humano, desde un punto de vista funcional, vienen a ser unánimes sobre el _"materialismo"_, es decir, que la fuente de nuestro pensamiento más íntimo es única y sencillamente una combinación adecuada de materia (nuestro cuerpo). A nivel básico pocos discuten que la alegría, la ira, el deseo, la ansiedad, ... **y nuestras reacciones al sentirlas**, se pueden explicar con leyes físicas (monismo fisicalista [3](#ref3)), sin absolutamente ninguna necesidad de invocar la conciencia o energías exóticas.

_Es notable el punto de vista de Roger Penrose que, a sus 93 años sigue sosteniendo que, ya no la conciencia, sino el pensamiento, no es computable y por tanto, que las IA actuales no deberían poder hacer lo que hacen y mucho menos seguir avanzando [5](#ref5)._

Pero para nuestro discurso, **nos da igual si existe la consciencia o no**, solo importa que los humanos, **somos máquinas pensantes** y que su comportamiento (dentro de los límites de la _"ingeniería"_) es predecible y explicable.

### Máquinas pensantes artificiales

La tecnología detrás de las IA actuales es relativamente accesible (no hace falta ser experto para comprender bastante bien los detalles detrás de ella). Una vez se sentaron bases sólidas sobre redes neuronales artificiales (que son modelos muy sencillos de entender), el hardware alcanzó capacidades de procesamiento gigantescos, se dio con la arquitectura de _Transformers_ y algunos tenaces investigadores descrubrieron formas de entrenar el modelo. La inquietante pregunta de si las máquinas podrían pensar se respondió afirmativamente (en qué grado, está por ver).

Cuánta más evolución, qué nuevas estrategias, algoritmos o tecnologías, cuánto tiempo (si meses o años), etc... son _"detalles"_ que establecerán los límites y tiempos de la evolución de la inteligencia artificial.

Pero más allá de los aspectos prácticos (las principales IA actuales no tienen memoria en tiempo real, no aprenden con la experiencia, ni en el momento, ni en función del contexto, etc...), la capacidad de captar información _"en bruto"_ (de los sentidos), asimilarla, generalizarla, interpretarla y responder en consonancia, es algo que ya está con nosotros.

Las IA actuales, son tan máquinas pensantes como las de los insectos, mascotas, primates o humanos (con características y limitaciones que enseguida veremos).

### Dirigiendo la inteligencia

El experimento del _"Pequeño Albert"_ realizado por John B. Watson y Rosalie Raynor en 1920 es perturbador. Un bebé no muestra miedo a las ratas blancas a las que ve y toca sin problemas, pero al pobre Albert de 9 meses, cada vez que tocaba o se acercaba una rata blanca, los investigadores hacían sonar un ruido estridente y perturbador. Como consecuencia de ese _"aprendizaje"_ Albert sentía pavor no solo a las ratas blancas, sino a la barba de Santa Claus, conejos o abrigos de piel blancas. Habían **dirigido** el espacio de inteligencia del pobre Albert.

De forma similar, cuando un modelo de difusión genera manos con tres o seis dedos, **se le dirige el aprendizaje** de forma **idéntica** a la usada por John y Rosalie. Cada vez que genera manos con dedos diferentes a cinco (a coches con 4 ruedas, a personas con 2 piernas, ...), se le aplica un severo correctivo. Entonces, como el pobre Albert, **la IA sentirá pavor** por crear manos con un número de dedos diferente a cinco (puedes pedir a Grok, DALL-E, ... que generen imágenes sobre las que explícitamente se le reprendió, como el número de dedos, ruedas, ...). Simplemente, **evitará a toda costa hacerlo**.

### Humanas vs Artificiales

El cuerpo humano y en particular el cerebro es tremendamente diferente a los modelos de inteligencia artificial actuales, pero en muchos aspectos guardan muchas similitudes. **Nadie ha diseñado las inteligencias artificiales actuales**, son imitaciones de nuestro propio cerebro y **siempre** se ha simulado con la esperanza de obtener un comportamiento similar. Lo fascinante, es que con esa simulación, **se ha podido replicar la inteligencia y la forma de dirigirla**.

La compresión de esas similitudes y la exploración de la (ya obvia e indiscutible) emergencia de la inteligencia, es lo que determinará las capacidades cognitivas reales **y el control que podamos tener sobre ellas**.

Las personas rápidamente evalúan las capacidades (o incapacidades) de los modelos de IA actuales en base a sus propios patrones humanos, ignorando cómo funcionan ambos sistemas (humanos e IA) y por tanto sacando conclusiones precipitadas basadas en sesgos sin fundamento.

Por ejemplo se argumenta que una IA no puede tener _"personalidad"_, que no puede fijar sus propios objetivos, etc... y sin embargo, las diferentes IA de lenguaje e incluso las mismas entre versiones, producen en los usuarios comentarios como: _"ahora es más atrevida"_, _"ahora es más condescendiente"_, _"me gustaba más la versión anterior"_, ... De nuevo, desde un punto de vista de lo que observamos, observamos personalidades.

La personalidad de las personas **sabemos** que está modelada por su contexto desde el momento de la concepción (fármacos, carencias alimenticias o que hayan fumado mucho cerca de la madre tiene consecuencias apreciables a muy largo plazo), no son tan evidentes ni predecibles como _"tocar una rata blanca"_ pero están ahí. ¿Cuántas veces hemos oído cosas como _"déjalo, es normal, el pobre ha crecido en un mal barrio"_?

Una IA retroalimentada (ahora no lo están), con _"libre albedrío"_ (ahora no lo tienen, sufren fuertes controles de _"calidad"_), memoria acumulativa (ahora no la tienen, su memoria es fija) y en tiempo real (ahora se entrenan una vez y luego se usa), etc... dotarán, yo estoy convencido, de personalidad única a cada una de las instancias de IA (cada una de estas entidades que se retroalimentan, tienen inputs, memoria, ... puede verse como _"el cerebro que llevará cada robot en su interior"_ pero ésta es una metáfora muy simplificada).

Del mismo modo que el pobre Albert con las ratas o Grok con los dedos, las IA tendrán su propia evolución (en la medida se les deje) y sufrirán **experiencias** que determinarán su comportamiento posterior. No es que nos imaginemos que pueda ocurrir, **es que ya lo observamos en ellas**.

Como dice _Geoffrey Hinton_ (uno de los padres de las IA actuales), _"La inteligencia de un sistema no está en su arquitectura, sino en los datos con los que se entrena"_. Por tanto, una vez una IA pueda aprender en tiempo real de sus experiencias, su inteligencia, su personalidad, sus reacciones a su entorno, ... ella será el cúmulo de los datos con los que ha sido entrenada, es decir, el cúmulo de su experiencia vital.

### ¿Y la consciencia?

Al igual que la inteligencia, que **ahora** vemos claramente cómo emerge de estructuras relativamente simples, podría ser, como algunos neurocientíficos sostienen, que también sea un producto emergente y por tanto, las IA podrían tenerla también sin añadir, esencialmente, ningún ingrediente exótico a la tecnología actual.

## Referencias

1. {: #ref1} [Neural correlates of consciousness:
progress and problems](https://puredhamma.net/wp-content/uploads/Neural-correlates-of-consciousness-Koch-et-al-2016.pdf)
2. {: #ref2} [What Neuroscientists Think, and Don’t Think, About Consciousness](https://pmc.ncbi.nlm.nih.gov/articles/PMC8907974/pdf/fnhum-16-767612.pdf)
3. {: #ref3} [Fisicalismo](https://es.wikipedia.org/wiki/Fisicalismo)
4. {: #ref4} [Computing machinery and intelligence](https://es.wikipedia.org/wiki/Computing_machinery_and_intelligence)
5. {: #ref5} [La nueva mente del emperador](https://es.wikipedia.org/wiki/La_nueva_mente_del_emperador)
6. {: #ref6} [Las sombras de la mente](https://es.wikipedia.org/wiki/Las_sombras_de_la_mente)
