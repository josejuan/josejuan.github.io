---
layout: post
title: Teor√≠a del desarrollo del software; detecci√≥n de bugs
author: josejuan
categories: software development
---

De forma recurrente me sorprendo por el (aparentemente) poco inter√©s en aplicar t√©cnicas _"ancestrales"_ al desarrollo del software que en otras √°reas han dado tan buenos resultados. La estad√≠stica y el c√°lculo de probabilidades (desde el genial _conde de Buffon_) se aplica con enorme √©xito en sistemas complejos de analizar de forma determinista. Desde hace bastante tiempo me pregunto por qu√© no veo cosas como _"Si la P d q cualquier c√≥digo tuyo tenga bugs es dl 50% y la d q tu test los descubra es dl 50%, tu c√≥digo es buggy en ~38% pues P‚âàB(1-D+DB)"_ <a href="https://twitter.com/__josejuan__/status/648138545660620800">üê¶ </a>.

En el desarrollo de _software_ sin duda hay muchas **opiniones**, pero no muchas t√©cnicas contrastadas con una s√≥lida base te√≥rica que ayuden (sobre todo a grandes equipos de desarrollo) a medir y dirigir los recursos hacia los _"puntos calientes"_ de la aplicaci√≥n. Ya no digamos para t√©cnicas m√°s sofisticadas como _"¬øTe imaginas un lenguaje que te pidiera anotaciones (ej. de tipo) bas√°ndose en la probabilidad de bug (rojo) o de optimizaci√≥n (naranja)?"_ <a href="https://twitter.com/__josejuan__/status/406050784984309760">üê¶ </a>.

Como son pocos y √©ste me ha gustado, me apetec√≠a tenerlo traducido.

**T√≠tulo original:** <a href="http://stevemcconnell.com/articles/gauging-software-readiness-with-defect-tracking/">_"Gauging Software Readiness With Defect Tracking"_</a> _(Vol. 14, No. 3, May/June 1997)_

-----------------------------------------------

En el competitivo mercado de software comercial, las empresas de software se sienten obligadas a lanzar software en el momento en que est√° listo. Su tarea es traicionera, pisando la l√≠nea divisoria entre liberar software de mala calidad temprano y software de alta calidad tarde. Una buena respuesta a la pregunta _"¬øEs el software lo suficientemente bueno para lanzarlo ahora?"_ puede ser cr√≠tico para la supervivencia de una empresa. La respuesta a veces se basa en el instinto visceral, pero varias t√©cnicas pueden poner este juicio sobre una base m√°s firme.

## Densidad de _bugs_

Una de las maneras m√°s f√°ciles de juzgar si un programa est√° listo para ser liberado es medir su densidad de _bugs_ - el n√∫mero de _bugs_ por l√≠nea de c√≥digo. Suponga que la primera versi√≥n de su producto, GigaTron 1.0, consistiera en 100.000 l√≠neas de c√≥digo, que usted detect√≥ 650 _bugs_ antes de la publicaci√≥n del software, y que se reportaron 50 _bugs_ m√°s despu√©s de la publicaci√≥n del software. Por lo tanto, el software ten√≠a un n√∫mero total de 700 _bugs_, y una densidad de _bugs_ de 7 _bugs_ por cada mil l√≠neas de c√≥digo (KLOC).

Supongamos que GigaTron 2.0 consisti√≥ en 50.000 l√≠neas de c√≥digo adicionales, que usted detect√≥ 400 _bugs_ antes de la liberaci√≥n, y otros 75 despu√©s de la liberaci√≥n. La densidad total de _bugs_ de esa liberaci√≥n ser√≠a de 475 _bugs_ totales divididos entre 50.000 nuevas l√≠neas de c√≥digo, o 9.5 _bugs_ por KLOC.

Ahora suponga que est√° tratando de decidir si GigaTron 3.0 es lo suficientemente confiable como para entregarlo. Consta de 100.000 nuevas l√≠neas de c√≥digo, y ha detectado 600 _bugs_ hasta ahora, o 6 _bugs_ por KLOC. A menos que tenga una buena raz√≥n para pensar que su proceso de desarrollo ha mejorado con este proyecto, su experiencia le llevar√° a esperar entre 7 y 10 _bugs_ por KLOC. El n√∫mero de _bugs_ que usted debe intentar encontrar variar√° dependiendo del nivel de calidad que est√° buscando. Si desea eliminar el 95 por ciento de todos los _bugs_ antes de la liberaci√≥n, deber√° detectar entre 650 y 950 _bugs_ antes del lanzamiento. Esta t√©cnica sugiere que el producto no est√° listo para su env√≠o.

Cuantos m√°s datos de proyecto hist√≥ricos tenga, m√°s confianza tendr√° en sus objetivos de densidad de _bugs_ previos a la liberaci√≥n. Si usted tiene datos de s√≥lo dos proyectos y el rango es tan amplio como 7 a 10 _bugs_ por KLOC, eso deja mucho espacio para un juicio experto sobre si el tercer proyecto ser√° m√°s parecido al primero o segundo. Pero si usted ha rastreado los datos de _bugs_ para 10 proyectos y ha encontrado que su tasa promedio de _bugs_ de por vida es de 7.4 _bugs_ por KLOC con una desviaci√≥n est√°ndar de 0.4 _bugs_, usted puede tener confianza en esos datos.

## Agrupaci√≥n de _bugs_

Otra t√©cnica sencilla de predicci√≥n de _bugs_ consiste en separar los informes de _bugs_ en dos grupos. Ll√°melos grupo A y grupo B. A continuaci√≥n, realice un seguimiento de los _bugs_ en estos dos grupos por separado. La distinci√≥n entre los dos grupos es arbitraria. Podr√≠a poner todos los _bugs_ descubiertos los lunes, mi√©rcoles y fines de semana en el grupo A, y el resto de los _bugs_ en el grupo B. O podr√≠as dividir a su equipo de pruebas por el medio y poner la mitad de sus _bugs_ reportados en un grupo, la mitad en el otro. No importa realmente c√≥mo se haga la divisi√≥n, siempre y cuando ambos grupos de informes operen independientemente y ambos prueben el alcance completo del producto.

Una vez que se crea una distinci√≥n entre los dos grupos, se realiza un seguimiento del n√∫mero de _bugs_ notificados en el grupo A, el n√∫mero en el grupo B y (aqu√≠ est√° la parte importante) el n√∫mero de _bugs_ que se notifican tanto en el grupo A como en el grupo B. El n√∫mero de _bugs_ √∫nicos notificados en un momento dado es:

  _bugs_<sub>√önicos</sub> = _bugs_<sub>A</sub> + _bugs_<sub>B</sub> - _bugs_<sub>AyB</sub>

El n√∫mero de _bugs_ totales puede entonces ser aproximado por la f√≥rmula:

  _bugs_ <sub>Total</sub> = (_bugs_<sub>A</sub> * _bugs_<sub>B</sub>) / _bugs_<sub>AyB</sub>

Si el proyecto GigaTron 3.0 tiene 400 _bugs_ en el grupo A, 350 _bugs_ en el grupo B y 150 de los _bugs_ en ambos grupos, el n√∫mero de _bugs_ √∫nicos detectados ser√≠a de 400 + 350 - 150 = 600. Si el proyecto GigaTron 3.0 tiene 400 _bugs_ en el grupo A, 350 _bugs_ en el grupo B y 150 de los _bugs_ en ambos grupos, el n√∫mero de _bugs_ √∫nicos detectados ser√≠a de 400 + 350 - 150 = 600. El n√∫mero aproximado de _bugs_ totales ser√≠a 400 * 350 / 150 = 933. Esta t√©cnica sugiere que quedan por detectar aproximadamente 333 _bugs_ (aproximadamente un tercio de los _bugs_ totales estimados); el aseguramiento de la calidad en este proyecto todav√≠a tiene un largo camino por recorrer.

## Sembrado de _bugs_

La siembra de _bugs_ es una pr√°ctica en la que un grupo inserta intencionadamente _bugs_ en un programa para su detecci√≥n por otro grupo. La relaci√≥n entre el n√∫mero de _bugs_ detectados y el n√∫mero total de _bugs_ sembrados proporciona una idea aproximada del n√∫mero total de _bugs_ no sembrados que se han detectado.

Suponga que en GigaTron 3.0 ha introducido intencionalmente el programa con 50 errores. Para obtener el mejor efecto, los errores sembrados deben cubrir la totalidad de la funcionalidad del producto y toda la gama de severidades, desde errores de colisi√≥n hasta errores cosm√©ticos.

Suponga que en un punto del proyecto, cuando usted crea que las pruebas est√°n casi completas, mira el informe del _bug_ sembrado. Usted encuentra que se han reportado 31 _bugs_ sembrados y 600 _bugs_ _"reales"_. Se puede estimar el n√∫mero total de _bugs_ con la f√≥rmula:

  _reales_<sub>Totales</sub> = (_sembrados_<sub>Totales</sub> / _sembrados_<sub>Encontrados</sub>) * _reales_<sub>Encontrados</sub>

Esta t√©cnica sugiere que GigaTron 3.0 tiene aproximadamente 50 / 31 * 600 = 967 _bugs_ totales.

Para utilizar la siembra de _bugs_, debe sembrar los _bugs_ antes del comienzo de las pruebas cuya eficacia desea determinar. Si su prueba utiliza m√©todos manuales y no tiene una manera sistem√°tica de cubrir el mismo campo de pruebas dos veces, usted debe sembrar _bugs_ antes de que comience la prueba. Si su prueba utiliza pruebas de regresi√≥n completamente automatizadas, usted puede sembrar _bugs_ virtualmente en cualquier momento para determinar la efectividad de las pruebas automatizadas.

Un problema com√∫n con los programas de sembrado de _bugs_ es el olvido de eliminar los _bugs_ sembrados. Otro problema com√∫n es que la eliminaci√≥n de los _bugs_ sembrados introduce nuevos errores. Para prevenir estos problemas, aseg√∫rese de eliminar todos los _bugs_ sembrados antes de las pruebas finales del sistema y la liberaci√≥n del producto. Un est√°ndar de implementaci√≥n √∫til para los errores sembrados es exigir que s√≥lo se implementen a√±adiendo una o dos l√≠neas de c√≥digo que crean el error; este est√°ndar garantiza que puede eliminar los errores sembrados de forma segura simplemente eliminando las l√≠neas de c√≥digo err√≥neas.

## Modelado de _bugs_

Un colega m√≠o recientemente agreg√≥ varios cientos de l√≠neas de c√≥digo a un programa existente en una sola sesi√≥n. La primera vez que compil√≥ el c√≥digo, obtuvo una compilaci√≥n limpia sin errores. Su codificaci√≥n inicial parec√≠a ser perfecta. Sin embargo, cuando intent√≥ probar la nueva funcionalidad, descubri√≥ que no exist√≠a. Cuando reexamin√≥ su nuevo c√≥digo, descubri√≥ que su trabajo hab√≠a sido incrustado entre un preprocesador de macros que desactivaba el nuevo c√≥digo. Cuando movi√≥ el nuevo c√≥digo fuera del alcance de la macro, produjo el n√∫mero habitual de errores del compilador.

Con los _bugs_ de software, ninguna noticia suele ser mala noticia. Si el proyecto ha llegado a una etapa tard√≠a con pocos _bugs_ reportados, hay una tendencia natural a pensar: "Finalmente lo hicimos bien y creamos un programa con casi ning√∫n _bug_" En realidad, ninguna noticia es m√°s a menudo el resultado de pruebas insuficientes que de pr√°cticas superlativas de desarrollo.

Algunas de las herramientas m√°s sofisticadas de estimaci√≥n y control de proyectos de software contienen una funcionalidad de modelado de _bugs_ que puede predecir el n√∫mero de _bugs_ que se espera encontrar en cada punto del proyecto. Comparando los _bugs_ realmente detectados con el n√∫mero pronosticado, usted puede evaluar si su proyecto se mantiene al d√≠a con la detecci√≥n de _bugs_ o si se queda rezagado.

## Combinaciones

Evaluar las combinaciones de densidad de _bugs_, grupos de _bugs_ y siembra de _bugs_ le dar√° m√°s confianza de la que podr√≠a tener en cualquiera de las t√©cnicas individualmente. Examinando la densidad del _bug_ solo en GigaTron 3.0 sugiri√≥ que usted debe esperar 700 a 1000 _bugs_ totales, y que usted debe quitar 650 a 950 antes de la liberaci√≥n del producto para alcanzar el 95 por ciento de eliminaci√≥n del _bug_ antes de la liberaci√≥n. Si usted ha detectado 600 _bugs_, la informaci√≥n de densidad de _bugs_ por s√≠ sola podr√≠a llevarle a declarar el producto "casi listo para enviar", pero el an√°lisis de agrupaci√≥n de _bugs_ calcula que GigaTron 3.0 producir√° aproximadamente 933 _bugs_ totales. Comparando los resultados de esas dos t√©cnicas sugiere que usted debe esperar un conteo total de _bugs_ hacia el extremo superior del rango de densidad de _bugs_ en lugar del extremo inferior. Debido a que la t√©cnica de siembra de _bugs_ tambi√©n estima un n√∫mero total de _bugs_ en los 900s, GigaTron 3.0 parece ser un programa relativamente defectuoso.

## Recursos

La literatura popular no tiene mucho que decir sobre la predicci√≥n de _bugs_. Una excepci√≥n notable es el libro de Glenford Myers de 1976, Software Reliability (Wiley). Lawrence H. Putnam y Ware Myers discuten el tema espec√≠fico del modelado de _bugs_ con cierta profundidad en Measures for Excellence (Yourdon Press 1992).


### Referencias

* [Gauging Software Readiness With Defect Tracking](http://stevemcconnell.com/articles/gauging-software-readiness-with-defect-tracking/)
